{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju3qN9sX6HNs",
        "outputId": "ae014e1f-d7ed-4f6f-f723-0ca190a23943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58aE1efY6HJ3",
        "outputId": "75f77931-6a5e-4f0e-e3d0-1e09b2725a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim torch torchvision scikit-learn pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkHgCm-L6HHe",
        "outputId": "dd1c0bcb-c615-4a67-b32b-9a45acdec81e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Import Library\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "\n",
        "# Cek device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhlVk_xm6HD0",
        "outputId": "dee8b5f9-fd74-4c78-cda0-0f8c4a21cc7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data:\n",
            "   class                                              title  \\\n",
            "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
            "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
            "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
            "3      3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
            "4      3  Oil prices soar to all-time record, posing new...   \n",
            "\n",
            "                                         description  \\\n",
            "0  Reuters - Short-sellers, Wall Street's dwindli...   \n",
            "1  Reuters - Private investment firm Carlyle Grou...   \n",
            "2  Reuters - Soaring crude prices plus worries\\ab...   \n",
            "3  Reuters - Authorities have halted oil export\\f...   \n",
            "4  AFP - Tearaway world oil prices, toppling reco...   \n",
            "\n",
            "                                                text  label  \n",
            "0  Wall St. Bears Claw Back Into the Black (Reute...      2  \n",
            "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2  \n",
            "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2  \n",
            "3  Iraq Halts Oil Exports from Main Southern Pipe...      2  \n",
            "4  Oil prices soar to all-time record, posing new...      2  \n"
          ]
        }
      ],
      "source": [
        "# Path Dataset dan GloVe\n",
        "TRAIN_PATH = \"train.csv\"\n",
        "TEST_PATH = \"test.csv\"\n",
        "GLOVE_PATH = \"/content/glove.6B.100d.txt\"  # Path ke file GloVe\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "# Load Dataset\n",
        "train_df = pd.read_csv(TRAIN_PATH, header=None, names=[\"class\", \"title\", \"description\"])\n",
        "test_df = pd.read_csv(TEST_PATH, header=None, names=[\"class\", \"title\", \"description\"])\n",
        "\n",
        "# Gabungkan title dan description\n",
        "train_df[\"text\"] = train_df[\"title\"].fillna(\"\") + \". \" + train_df[\"description\"].fillna(\"\")\n",
        "test_df[\"text\"] = test_df[\"title\"].fillna(\"\") + \". \" + test_df[\"description\"].fillna(\"\")\n",
        "\n",
        "# Encode label\n",
        "label_encoder = LabelEncoder()\n",
        "train_df[\"label\"] = label_encoder.fit_transform(train_df[\"class\"])\n",
        "test_df[\"label\"] = label_encoder.transform(test_df[\"class\"])\n",
        "\n",
        "print(\"Sample data:\")\n",
        "print(train_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_path, embedding_dim):\n",
        "    word_to_idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "    embedding_matrix = [np.zeros(embedding_dim), np.random.uniform(-0.25, 0.25, embedding_dim)]\n",
        "\n",
        "    print(\"Loading GloVe embeddings...\")\n",
        "    with open(glove_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            parts = line.split()\n",
        "            word = parts[0]\n",
        "            vector = np.array(parts[1:], dtype=np.float32)\n",
        "            word_to_idx[word] = len(word_to_idx)\n",
        "            embedding_matrix.append(vector)\n",
        "\n",
        "    embedding_matrix = np.array(embedding_matrix)\n",
        "    print(\"GloVe embeddings loaded successfully!\")\n",
        "    return word_to_idx, torch.tensor(embedding_matrix, dtype=torch.float)\n",
        "\n",
        "word_to_idx, embedding_matrix = load_glove_embeddings(GLOVE_PATH, EMBEDDING_DIM)\n",
        "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8hplOfOlMHV",
        "outputId": "9691b5b8-c731-477f-de2b-70fa3f947809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading GloVe embeddings...\n",
            "GloVe embeddings loaded successfully!\n",
            "Embedding matrix shape: torch.Size([400002, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRTC-uf55neh"
      },
      "outputs": [],
      "source": [
        "# Tokenizer sederhana\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "# Dataset class\n",
        "class AGNewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, word_to_idx, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.word_to_idx = word_to_idx\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenisasi dan konversi ke indeks\n",
        "        tokens = tokenize(text)\n",
        "        token_ids = [self.word_to_idx.get(token, 1) for token in tokens]  # 1 = \"<UNK>\"\n",
        "\n",
        "        # Padding\n",
        "        if len(token_ids) < self.max_len:\n",
        "            token_ids += [0] * (self.max_len - len(token_ids))  # 0 = \"<PAD>\"\n",
        "        else:\n",
        "            token_ids = token_ids[:self.max_len]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(token_ids, dtype=torch.long),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2t-M3x7AQts"
      },
      "outputs": [],
      "source": [
        "# Dataset dan DataLoader\n",
        "MAX_LEN = 100\n",
        "train_dataset = AGNewsDataset(train_df[\"text\"].values, train_df[\"label\"].values, word_to_idx, MAX_LEN)\n",
        "test_dataset = AGNewsDataset(test_df[\"text\"].values, test_df[\"label\"].values, word_to_idx, MAX_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZpVSgxb5nbT"
      },
      "outputs": [],
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, embedding_matrix, n_heads, hidden_size, n_encoders, n_classes, dropout=0.5):\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "        vocab_size, embedding_dim = embedding_matrix.shape\n",
        "\n",
        "        # Load GloVe embeddings\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)\n",
        "        self.positional_encoding = nn.Embedding(MAX_LEN, embedding_dim)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=n_heads, dim_feedforward=hidden_size, dropout=dropout)\n",
        "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=n_encoders)\n",
        "\n",
        "        self.fc = nn.Linear(embedding_dim * MAX_LEN, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x) + self.positional_encoding(torch.arange(MAX_LEN, device=DEVICE))\n",
        "        x = self.encoder(x.permute(1, 0, 2))  # (seq_len, batch_size, emb_dim)\n",
        "        x = x.permute(1, 0, 2).contiguous().view(x.size(1), -1)  # Flatten\n",
        "        return self.fc(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi Model\n",
        "model = TransformerClassifier(\n",
        "    embedding_matrix=embedding_matrix,\n",
        "    n_heads=4,\n",
        "    hidden_size=256,\n",
        "    n_encoders=2,\n",
        "    n_classes=len(label_encoder.classes_)\n",
        ").to(DEVICE)\n",
        "\n",
        "# Optimizer dan Loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training Function\n",
        "def train_epoch(model, data_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in data_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        labels = batch[\"label\"].to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfIDjDSQluQr",
        "outputId": "cc5341f0-cb61-4a6d-eee0-2b5e01ce1940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            labels = batch[\"label\"].to(DEVICE)\n",
        "            outputs = model(input_ids)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "    return accuracy_score(true_labels, predictions)\n",
        "\n",
        "# Train model with timing\n",
        "import time\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    acc = evaluate(model, test_loader)\n",
        "    end_time = time.time()\n",
        "    epoch_time = end_time - start_time\n",
        "    print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {train_loss:.4f}, Test Accuracy: {acc:.4f}, Time: {epoch_time:.2f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOHiBJQfmpsr",
        "outputId": "32696902-2fce-4ccf-b533-88f4eeffaabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5: Train Loss: 0.3409, Test Accuracy: 0.8891, Time: 28.78s\n",
            "Epoch 2/5: Train Loss: 0.3318, Test Accuracy: 0.8834, Time: 35.19s\n",
            "Epoch 3/5: Train Loss: 0.3234, Test Accuracy: 0.8805, Time: 28.91s\n",
            "Epoch 4/5: Train Loss: 0.3154, Test Accuracy: 0.8928, Time: 28.92s\n",
            "Epoch 5/5: Train Loss: 0.3099, Test Accuracy: 0.8917, Time: 29.83s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "torch.save(model.state_dict(), \"transformer_with_glove.pth\")\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzRnmHVOnvr_",
        "outputId": "3239df2c-a0e6-41e3-f860-2d464a827dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}